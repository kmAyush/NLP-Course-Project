{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmAyush/Video-Dubbing-with-Lip-Synchronization/blob/main/Text%20Translation/Bidir_word_trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTx56L38_mIR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import  nltk.translate.bleu_score as bleu\n",
        "\n",
        "from io import open\n",
        "import unicodedata\n",
        "import random\n",
        "import tqdm.auto as tqdm\n",
        "\n",
        "from nltk.translate import bleu_score\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import json\n",
        "import os\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://drive.google.com/file/d/1-3yAkoJtKfNyr5bHh2qayuQVOeMYTPVO/view?usp=drive_link\"\n",
        "id = url.split('/')[-2]\n",
        "file_url = f'https://drive.google.com/uc?id={id}'\n",
        "destination_location = \"/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/\"\n",
        "gdown.download(file_url , destination_location, quiet=False )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "zPjE3HUgwD6V",
        "outputId": "d333dc19-9777-4133-a9dc-25e6d13119d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-3yAkoJtKfNyr5bHh2qayuQVOeMYTPVO\n",
            "To: /content/Video-Dubbing-with-Lip-Synchronization/Text Translation/english.pkl\n",
            "100%|██████████| 741k/741k [00:00<00:00, 67.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/english.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://drive.google.com/file/d/1-ACb3okGOeYACwCofyOIVla6udM5gVnl/view?usp=drive_link\"\n",
        "id = url.split('/')[-2]\n",
        "file_url = f'https://drive.google.com/uc?id={id}'\n",
        "destination_location = \"/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/\"\n",
        "gdown.download(file_url , destination_location, quiet=False )"
      ],
      "metadata": {
        "id": "wQQlDrqgCuRd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "bc8c4341-b873-40e0-922e-17796ec0084d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-ACb3okGOeYACwCofyOIVla6udM5gVnl\n",
            "To: /content/Video-Dubbing-with-Lip-Synchronization/Text Translation/hindi.pkl\n",
            "100%|██████████| 1.08M/1.08M [00:00<00:00, 28.7MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/hindi.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://drive.google.com/file/d/1ZjhBUE0w-SB6kO9_GFrrRIqCzKzGtQHC/view?usp=sharing\"\n",
        "\n",
        "id = url.split('/')[-2]\n",
        "file_url = f'https://drive.google.com/uc?id={id}'\n",
        "destination_location = \"/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/\"\n",
        "gdown.download(file_url , destination_location, quiet=False )"
      ],
      "metadata": {
        "id": "C68kl3PHCudA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "d350af90-ef27-41ea-912e-2efac7886427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZjhBUE0w-SB6kO9_GFrrRIqCzKzGtQHC\n",
            "To: /content/Video-Dubbing-with-Lip-Synchronization/Text Translation/new_data.csv\n",
            "100%|██████████| 7.62M/7.62M [00:00<00:00, 33.1MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/new_data.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/new_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "df = df.iloc[:,:2]\n",
        "df = df.dropna()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "izfDocOxCuhs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b1706221-019a-4f68-c7b4-5a4d47379498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0                (LAUGHS) Oh, you're getting a bill.   \n",
              "1                                Welcome, Professor.   \n",
              "2      PROFESSOR X: Are we\\ndestined down this path?   \n",
              "3  We are at site coordinates\\napproximately 15H-...   \n",
              "4                                     What was that?   \n",
              "\n",
              "                                          Hindi  \n",
              "0          (हंसते हुए) ओह, आपको बिल मिल रहा है।  \n",
              "1                     आपका स्वागत है, प्रोफेसर.  \n",
              "2  प्रोफेसर एक्स: क्या हम हैं?\\nइस पथ पर नियति?  \n",
              "3    हम साइट निर्देशांक पर हैं\\nलगभग 15एच-32...  \n",
              "4                                   वह क्या था?  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56923f01-867f-40b8-be1f-b6c6e9ffe440\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(LAUGHS) Oh, you're getting a bill.</td>\n",
              "      <td>(हंसते हुए) ओह, आपको बिल मिल रहा है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Welcome, Professor.</td>\n",
              "      <td>आपका स्वागत है, प्रोफेसर.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PROFESSOR X: Are we\\ndestined down this path?</td>\n",
              "      <td>प्रोफेसर एक्स: क्या हम हैं?\\nइस पथ पर नियति?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We are at site coordinates\\napproximately 15H-...</td>\n",
              "      <td>हम साइट निर्देशांक पर हैं\\nलगभग 15एच-32...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What was that?</td>\n",
              "      <td>वह क्या था?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56923f01-867f-40b8-be1f-b6c6e9ffe440')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-56923f01-867f-40b8-be1f-b6c6e9ffe440 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-56923f01-867f-40b8-be1f-b6c6e9ffe440');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7f65da77-5b45-4c4f-8c1e-25658b733e8b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7f65da77-5b45-4c4f-8c1e-25658b733e8b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7f65da77-5b45-4c4f-8c1e-25658b733e8b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 60007,\n  \"fields\": [\n    {\n      \"column\": \"English\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56770,\n        \"samples\": [\n          \"Bring your mask if you want.\\nI'm getting used to it.\",\n          \"Surrendering my father's ship\\nwill not guarantee survival, Mr. Phelps.\",\n          \"You always do.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hindi\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 55963,\n        \"samples\": [\n          \"\\u0905\\u0930\\u0947! \\u0906\\u092a \\u0915\\u094d\\u092f\\u093e \\u0915\\u0930 \\u0930\\u0939\\u0947 \\u0939\\u094b?\",\n          \"\\u091c\\u0948\\u0938\\u093e \\u0915\\u093f \\u0906\\u092a\\u0915\\u093e \\u0939\\u0948.\",\n          \"\\u0906\\u0913, \\u090f\\u0921\\u0940. \\u0924\\u0941\\u092e \\u092e\\u0947\\u0930\\u0947 \\u0939\\u0940 \\u0909\\u092e\\u094d\\u092e\\u0940\\u0926 \\u0915\\u0930 \\u0930\\u0939\\u0947 \\u0939\\u0948\\u0902\\u0964\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/english.pkl'\n",
        "with open(file_path, 'rb') as file:\n",
        "   tokenizer_eng = pickle.load(file)\n",
        "\n",
        "file_path = '/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/hindi.pkl'\n",
        "with open(file_path, 'rb') as file:\n",
        "   tokenizer_hin = pickle.load(file)\n",
        "\n",
        "eng_vocab = tokenizer_eng.get_vocab()\n",
        "hin_vocab = tokenizer_hin.get_vocab()\n",
        "\n",
        "pairs = [[tokenizer_eng.encode(\"<SOS>\").ids+ tokenizer_eng.encode(row['English']).ids + tokenizer_eng.encode(\"<EOS>\").ids, tokenizer_hin.encode(\"<SOS>\").ids + tokenizer_hin.encode(row['Hindi']).ids + tokenizer_hin.encode(\"<EOS>\").ids] for index, row in df.iterrows()]"
      ],
      "metadata": {
        "id": "Qcb9k3e9DMTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "pairs_train, pairs_rest = train_test_split(pairs, test_size=0.2, random_state=42)\n",
        "pairs_valid, pairs_test = train_test_split(pairs_rest, test_size=0.5, random_state=42)\n",
        "df_test = pd.DataFrame(pairs_test,columns = ['English','Hindi'])\n",
        "df_train = pd.DataFrame(pairs_train,columns = ['English','Hindi'])"
      ],
      "metadata": {
        "id": "1Ddr8AB2QHSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, pairs):\n",
        "        self.pairs = pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_data, target_data = self.pairs[idx]\n",
        "\n",
        "        return torch.tensor(input_data), torch.tensor(target_data)\n",
        "\n",
        "def pad_collate(batch):\n",
        "    input_seqs, target_seqs = zip(*batch)\n",
        "\n",
        "    input_seqs_padded = torch.nn.utils.rnn.pad_sequence(input_seqs, batch_first=True)\n",
        "    target_seqs_padded = torch.nn.utils.rnn.pad_sequence(target_seqs, batch_first=True)\n",
        "\n",
        "    return input_seqs_padded, target_seqs_padded\n",
        "\n",
        "\n",
        "dataset_tr = MyDataset(pairs)\n",
        "dataset_val = MyDataset(pairs_valid)\n",
        "dataset_te = MyDataset(pairs_test)\n",
        "# Create a DataLoader\n",
        "batch_size = 8 # Set your desired batch size\n",
        "train_dataloader = DataLoader(dataset_tr, batch_size=batch_size, collate_fn=pad_collate)\n",
        "test_dataloader = DataLoader(dataset_te, batch_size=batch_size, collate_fn=pad_collate)\n",
        "valid_dataloader = DataLoader(dataset_val, batch_size=batch_size, collate_fn=pad_collate)\n"
      ],
      "metadata": {
        "id": "833ugnM4QHVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionModule(torch.nn.Module):\n",
        "    \"\"\" Implements an attention module \"\"\"\n",
        "\n",
        "    def __init__(self, input_size):\n",
        "        \"\"\" Initializes the attention module.\n",
        "            Feel free to declare any parameters as required. \"\"\"\n",
        "\n",
        "        super(AttentionModule, self).__init__()\n",
        "        self.W_key = nn.Linear((2*input_size), input_size)\n",
        "        self.W_query = nn.Linear(input_size, input_size)\n",
        "        self.W_value =nn.Linear((2*input_size), input_size)\n",
        "\n",
        "\n",
        "    def forward(self, encoder_outputs, decoder_hidden_state):\n",
        "        \"\"\" Performs a forward pass over the module, computing attention scores for inputs.\n",
        "\n",
        "        Args:\n",
        "            encoder_outputs (torch.Tensor): Output representations from the encoder, of shape [batch_size?, src_seq_len, output_dim].\n",
        "            decoder_hidden_state (torch.Tensor): Hidden state from the decoder at current time step, of appropriate shape as per RNN unit (with optional batch dim).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Attentions scores for given inputs, of shape [batch_size?, 1, src_seq_len]\n",
        "        \"\"\"\n",
        "        keys = self.W_key(encoder_outputs)  # batch,seq_length, hidden_size\n",
        "        values = self.W_value(encoder_outputs)   # batch,seq_length, hidden_size\n",
        "\n",
        "        # decoder_hidden_state ==  num_layer,N, hid_size\n",
        "\n",
        "        num_layers = decoder_hidden_state.size(0)\n",
        "        decoder_hidden_state = decoder_hidden_state[num_layers-1].unsqueeze(1)  # N , 1, hidden\n",
        "        query = self.W_query(decoder_hidden_state)  #  batch,1 ,hidden_size\n",
        "        query = query.transpose(1, 2)  # (batch size, hidden size, 1)\n",
        "\n",
        "        weights = torch.matmul(keys, query)  # batch , sequence, 1\n",
        "        weights = F.softmax(weights, dim = 1)   # (batch, sequence,  1)\n",
        "\n",
        "        context_vector = weights * values  # N, seq_length , hidden\n",
        "\n",
        "        context_vector = torch.sum(context_vector, dim = 1, keepdim = True) # N, 1, hidden\n",
        "\n",
        "        return context_vector, weights"
      ],
      "metadata": {
        "id": "Wn7x2ed83ncs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RNNEncoderDecoderLMWithAttention(torch.nn.Module):\n",
        "    \"\"\" Implements an Encoder-Decoder network, using RNN units, augmented with attention. \"\"\"\n",
        "\n",
        "    def __init__(self,src_vocab_size, tgt_vocab_size, embd_dims, hidden_size, num_layers=1, dropout=0.1, teacher_force_ratio = 1 ):\n",
        "        \"\"\" Initializes the encoder-decoder network, implemented via RNNs.\n",
        "\n",
        "        Args:\n",
        "            src_vocab_size (int): Source vocabulary size.\n",
        "            tgt_vocab_size (int): Target vocabulary size.\n",
        "            embd_dims (int): Embedding dimensions.\n",
        "            hidden_size (int): Size/Dimensions for the hidden states.\n",
        "        \"\"\"\n",
        "\n",
        "        super(RNNEncoderDecoderLMWithAttention, self).__init__()\n",
        "\n",
        "        self._dummy_param = torch.nn.Parameter(torch.Tensor(0), requires_grad=False)\n",
        "        self.src_vocab_size = src_vocab_size\n",
        "        self.tgt_vocab_size = tgt_vocab_size\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.dropout_enc = nn.Dropout(dropout)\n",
        "        self.dropout_dec = nn.Dropout(dropout)\n",
        "        self.teacher_force_ratio = teacher_force_ratio\n",
        "        self.enc_pad_index = 0\n",
        "\n",
        "        self.tgt_pad_index = 0\n",
        "        self.tgt_start_index = 1\n",
        "        self.tgt_end_index = 2\n",
        "\n",
        "        self.attension_module = AttentionModule(hidden_size)\n",
        "\n",
        "        self.encoder_embedding = torch.nn.Embedding(src_vocab_size, embd_dims)\n",
        "        self.encoder_lstm = nn.LSTM(embd_dims, hidden_size,num_layers = num_layers , batch_first = True, dropout = dropout, bidirectional=True)\n",
        "\n",
        "        self.decoder_embedding = torch.nn.Embedding(tgt_vocab_size, embd_dims)\n",
        "        self.decoder_lstm = nn.LSTM(embd_dims+hidden_size, hidden_size,num_layers = num_layers, batch_first = True, dropout = dropout)\n",
        "        self.decoder_output_fc = nn.Linear(hidden_size, embd_dims)\n",
        "        self.dec_out_embed = nn.Linear(embd_dims,tgt_vocab_size, bias = False)\n",
        "\n",
        "        self.dec_out_embed.weight = self.decoder_embedding.weight\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        return self._dummy_param.device\n",
        "\n",
        "    def forward(self, inputs, decoder_inputs=None, decoder_hidden_state=None, output_attention=False ):\n",
        "        \"\"\" Performs a forward pass over the encoder-decoder network.\n",
        "\n",
        "            Accepts inputs for the encoder, inputs for the decoder, and hidden state for\n",
        "                the decoder to continue generation after the given input.\n",
        "\n",
        "        Args:\n",
        "            inputs (torch.Tensor): tensor of shape [batch_size?, src_seq_len]\n",
        "            decoder_inputs (torch.Tensor): Decoder inputs, as tensor of shape [batch_size?, 1]\n",
        "            decoder_hidden_state (any): tensor to represent decoder hidden state from time step T-1.\n",
        "            output_attention (bool): If true, this function should also return the\n",
        "                associated attention weights for the time step, of shape [batch_size?, 1, src_seq_len].\n",
        "\n",
        "        Returns:\n",
        "            tuple[torch.Tensor, any]: output from the decoder, and associated hidden state for the next step.\n",
        "\n",
        "            Decoder outputs should be log probabilities over the target vocabulary.\n",
        "\n",
        "        Example:\n",
        "        >>> model = RNNEncoderDecoderWithAttention(*args, **kwargs)\n",
        "        >>> output, hidden = model(..., output_attention=False)\n",
        "        >>> output, hidden, attn_weights = model(..., output_attention=True)\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = inputs.size(0)\n",
        "        seq_length = decoder_inputs.size(1) if decoder_inputs != None else inputs.size(1)\n",
        "\n",
        "        encoder_input_embed = self.encoder_embedding(inputs)\n",
        "        encoder_output, (encoder_hidden ,cell_encoder )= self.encoder_lstm(encoder_input_embed)\n",
        "\n",
        "        decoder_hidden = encoder_hidden[:self.num_layers,:,:]\n",
        "        decoder_cell = cell_encoder[:self.num_layers,:,:]\n",
        "        decoder_input_test = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(self.tgt_start_index)\n",
        "\n",
        "\n",
        "        pred_output_prob = []\n",
        "        weights  = []\n",
        "        for i in range(1,seq_length):\n",
        "\n",
        "            decoder_input_embed = self.decoder_embedding(decoder_input_test)\n",
        "            context_vector, wts = self.attension_module(encoder_output, decoder_hidden)  #in biderectional lstm out sieze(N,SEQ,2*HIDD)\n",
        "            decoder_input_lstm = torch.cat((decoder_input_embed, context_vector), dim = 2)\n",
        "\n",
        "            dec_output, (decoder_hidden,decoder_cell) = self.decoder_lstm(decoder_input_lstm, (decoder_hidden,decoder_cell))\n",
        "            out_tgt = self.decoder_output_fc(dec_output)\n",
        "            out_tgt_embd = self.dec_out_embed(out_tgt)\n",
        "            pred_output = F.log_softmax(out_tgt_embd, dim = -1)\n",
        "\n",
        "            if decoder_inputs != None:\n",
        "              teacher_frc = torch.rand(1, 1)\n",
        "              if teacher_frc < self.teacher_force_ratio:\n",
        "                 decoder_input_test = decoder_inputs[:, i].unsqueeze(1)\n",
        "\n",
        "              else:\n",
        "                 _, topi = pred_output.topk(1)\n",
        "                 decoder_input_test = topi.squeeze(-1).detach()\n",
        "            else:\n",
        "               _, topi = pred_output.topk(1)\n",
        "               decoder_input_test = topi.squeeze(-1).detach()\n",
        "\n",
        "            pred_output_prob.append(pred_output)\n",
        "            wts = wts.squeeze(0).squeeze(1)\n",
        "            weights.append(wts)\n",
        "\n",
        "\n",
        "        pred_output_prob = torch.cat(pred_output_prob, dim = 1)\n",
        "        weights = torch.stack(weights)\n",
        "\n",
        "\n",
        "        return pred_output_prob,weights  #, decoder_hidden, decoder_cell , encoder_output"
      ],
      "metadata": {
        "id": "4bzPhPFA3ngF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_paddings(sequence,pad_token):\n",
        "  while(sequence[-1] == pad_token):\n",
        "    sequence = sequence[:-1]\n",
        "\n",
        "  return sequence\n",
        "\n",
        "\n",
        "def rnn_greedy_generate(model, seq_x, max_length=5):\n",
        "    \"\"\" Given a source string, translate it to the target language using the trained model.\n",
        "        This function should perform greedy sampling to generate the results.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): RNN Type Encoder-Decoder Model\n",
        "        seq_x (str): Input string to translate.\n",
        "        src_tokenizer (Tokenizer): Source language tokenizer.\n",
        "        tgt_tokenizer (Tokenizer): Target language tokenizer.\n",
        "        max_length (int): Maximum length of the target sequence to decode.\n",
        "\n",
        "    Returns:\n",
        "        str: Generated string for the given input in the target language.\n",
        "    \"\"\"\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    input_length = len(seq_x)\n",
        "\n",
        "    for i in range(5):\n",
        "      seq_x.append(0)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    input_tokens = torch.tensor(seq_x).unsqueeze(0)\n",
        "    input_tokens = input_tokens.to(device)\n",
        "\n",
        "    output_probs,_ = model(input_tokens)\n",
        "    tgt_tokens = torch.argmax(output_probs, dim = 2).squeeze(0).tolist()\n",
        "\n",
        "    tgt_tokens = remove_paddings(tgt_tokens,0)\n",
        "    trans_seq = tokenizer_hin.decode(tgt_tokens[:-1])\n",
        "    return trans_seq"
      ],
      "metadata": {
        "id": "J7J_J6WHDxna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Evaluator:\n",
        "    \"\"\" Class to handle all the logic concerning the evaluation of trained models.  \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\" Initializes the evaluator.\n",
        "\n",
        "        Args:\n",
        "            src_tokenizer (Tokenizer): Tokenizer for input strings in the source language.\n",
        "            tgt_tokenizer (Tokenizer): Tokenizer for output strings in the target language.\n",
        "        \"\"\"\n",
        "\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.decoding_method = None\n",
        "\n",
        "    def set_decoding_method(self, decoding_method):\n",
        "        \"\"\" Sets the decoding method to use with models.\n",
        "                The evaluation function will use the set decoding method to generate outputs from the model.\n",
        "\n",
        "        Args:\n",
        "            decoding_method (function): Decoding method.\n",
        "                Must accept the model instance, the input string, and tokenizers as arguments.\n",
        "                Can accept additional arguments if required.\n",
        "        \"\"\"\n",
        "\n",
        "        self.decoding_method = decoding_method\n",
        "\n",
        "    @staticmethod\n",
        "    def decompose(string):\n",
        "        \"\"\" Decomposes a string into a set of tokens.\n",
        "\n",
        "        Args:\n",
        "            string (str): String to decompose.\n",
        "\n",
        "        Returns:\n",
        "            list[str]: List of characters from the string.\n",
        "        \"\"\"\n",
        "        return unicodedata.normalize('NFKD', string).encode('utf-8')\n",
        "\n",
        "    @staticmethod\n",
        "    def levenshtein_distance(string1, string2):\n",
        "        \"\"\" Computes the levensthein distance between two strings.\n",
        "\n",
        "        Args:\n",
        "            string1 (list[any]): Sequence A.\n",
        "            string2 (list[any]): Sequence B.\n",
        "\n",
        "        Returns:\n",
        "            tuple[int, int, int]: Number of insertions + deletions, substitutions and no-ops.\n",
        "        \"\"\"\n",
        "\n",
        "        costs = [\n",
        "            [ 0 for j in range(len(string2)+1) ]\n",
        "            for i in range(len(string1)+1)\n",
        "        ]\n",
        "\n",
        "        # Prepare matrix of costs.\n",
        "        for i in range(len(string1)+1): costs[i][0] = i\n",
        "        for j in range(len(string2)+1): costs[0][j] = j\n",
        "        for i in range(1, len(string1)+1):\n",
        "            for j in range(1, len(string2)+1):\n",
        "                costs[i][j] = min(\n",
        "                    costs[i][j-1] + 1,\n",
        "                    costs[i-1][j] + 1,\n",
        "                    costs[i-1][j-1] + (0 if string1[i-1] == string2[j-1] else 1)\n",
        "                )\n",
        "\n",
        "        # Decode matrix in backward manner for actual operation counts.\n",
        "        c_ins_del, c_sub, c_noop = 0, 0, 0\n",
        "\n",
        "        i, j = len(string1), len(string2)\n",
        "        while i > 0 or j > 0:\n",
        "            if i > 0 and costs[i][j] == costs[i-1][j] + 1:\n",
        "                c_ins_del += 1\n",
        "                i -= 1\n",
        "            elif j > 0 and costs[i][j] == costs[i][j-1] + 1:\n",
        "                c_ins_del += 1\n",
        "                j -= 1\n",
        "            elif i > 0 and j > 0:\n",
        "                if string1[i-1] == string2[j-1]:\n",
        "                    c_noop += 1\n",
        "                else:\n",
        "                    c_sub += 1\n",
        "                i, j = i-1, j-1\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        return c_ins_del, c_sub, c_noop\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy(y_true, y_pred):\n",
        "        \"\"\" Computes the accuracy of the predictions, against a reference set of predictions.\n",
        "\n",
        "        Args:\n",
        "            y_true (list[str]): Actual translations.\n",
        "            y_pred (list[str]): Generated translations.\n",
        "\n",
        "        Returns:\n",
        "            float: Accuracy score, between 0 and 1.\n",
        "        \"\"\"\n",
        "        return sum(yi_true == yi_pred for yi_true, yi_pred in zip(y_true, y_pred)) / len(y_pred)\n",
        "\n",
        "    @classmethod\n",
        "    def char_error_rate(cls, y_true, y_pred):\n",
        "        \"\"\" Computes the character level error rate (CER) of the set of\n",
        "            predictions against the reference translations.\n",
        "\n",
        "        Args:\n",
        "            y_true (list[str]): Actual translations.\n",
        "            y_pred (list[str]): Generated translations.\n",
        "\n",
        "        Returns:\n",
        "            float: CER score, between 0 and 1. Lower the better.\n",
        "        \"\"\"\n",
        "        cer_score = 0\n",
        "        for yi_true, yi_pred in zip(y_true, y_pred):\n",
        "            yi_true, yi_pred = cls.decompose(yi_true), cls.decompose(yi_pred)\n",
        "            c_ins_del, c_sub, c_noop = cls.levenshtein_distance(yi_true, yi_pred)\n",
        "            cer_score += (c_ins_del + c_sub) / (c_ins_del + c_sub + c_noop)\n",
        "\n",
        "        return cer_score / len(y_true)\n",
        "\n",
        "    def token_error_rate(self, y_true, y_pred):\n",
        "        \"\"\" Computes the token level error rate (TER) of the set of\n",
        "            predictions against the reference translations.\n",
        "\n",
        "        Args:\n",
        "            y_true (list[str]): Actual translations.\n",
        "            y_pred (list[str]): Generated translations.\n",
        "\n",
        "        Returns:\n",
        "            float: TER score, between 0 and 1. Lower the better.\n",
        "        \"\"\"\n",
        "\n",
        "        ter_score = 0\n",
        "\n",
        "        for yi_true, yi_pred in zip(y_true, y_pred):\n",
        "            yi_true = tokenizer_hin.encode(yi_true)\n",
        "            yi_pred = tokenizer_hin.encode(yi_pred)\n",
        "            t_ins_del, t_sub, t_noop = self.levenshtein_distance(yi_true, yi_pred)\n",
        "            ter_score += (t_ins_del + t_sub) / (t_ins_del + t_sub + t_noop)\n",
        "\n",
        "        return ter_score / len(y_true)\n",
        "\n",
        "    @classmethod\n",
        "    def bleu_score(cls, y_true, y_pred):\n",
        "        \"\"\" Computes the average BLEU score of the set of predictions against the reference translations.\n",
        "\n",
        "            Uses default parameters and equal weights for all n-grams, with max N = 4. (Thus computes BLEU-4).\n",
        "            Uses a smoothing method for the case of missing n-grams.\n",
        "\n",
        "        Args:\n",
        "            y_true (list[str]): Actual translations.\n",
        "            y_pred (list[str]): Generated translations.\n",
        "\n",
        "        Returns:\n",
        "            float: BLEU-4 score, the higher the better.\n",
        "        \"\"\"\n",
        "\n",
        "        y_true = [ [ cls.decompose(yi) ] for yi in y_true ]\n",
        "        y_pred = [ cls.decompose(yi) for yi in y_pred ]\n",
        "\n",
        "        smoothing = bleu_score.SmoothingFunction()\n",
        "\n",
        "        return bleu_score.corpus_bleu(\n",
        "            y_true, y_pred,\n",
        "            smoothing_function=smoothing.method1\n",
        "        )\n",
        "\n",
        "    def evaluate(self, model, data, reference_outputs):\n",
        "        \"\"\" Performs the evaluation of a specified model over given data.\n",
        "\n",
        "        Args:\n",
        "            model_path (str): Path to load the model from. Must have a model.pt file.\n",
        "            data (list[str]): List of input strings to translate.\n",
        "            reference_outputs (list[str]): List of output strings to use as reference.\n",
        "            decoding_kwargs (dict[str, any]): Additional arguments to forward to the decoding method.\n",
        "                This could be for instance, max_length for a greedy decoding method.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If the decoding method is not set apriori.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.decoding_method is None:\n",
        "            raise ValueError(f\"{self.evaluate.__name__}: no decoding method is set, assign before use.\")\n",
        "        model.to(self.device)\n",
        "        model.eval()\n",
        "\n",
        "        # Generate outputs.\n",
        "        generated_outputs = []\n",
        "        with torch.no_grad():\n",
        "            for seq_x in data:\n",
        "                generated_outputs.append(self.decoding_method(\n",
        "                    model, seq_x))\n",
        "        accuracy_score = self.accuracy(reference_outputs, generated_outputs)\n",
        "        blue_score     = self.bleu_score(reference_outputs, generated_outputs)\n",
        "\n",
        "        print(\"EVALUATION:\", \">\", \"accuracy:\", f\"{accuracy_score:.2%}\")\n",
        "        print(\"EVALUATION:\", \">\", \"BLEU    :\", f\"{blue_score:.4f}\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "kt0qfAQADylk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sync_vram():\n",
        "    \"\"\" Synchronizes the VRAM across the GPUs, reclaiming unused memory. \"\"\"\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "df_sample =df_test\n",
        "true_data = [tokenizer_hin.decode(tokens) for tokens in df_sample['Hindi']]"
      ],
      "metadata": {
        "id": "hVGJV485Dyob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    \"\"\" Performs model training in a model-agnostic manner.\n",
        "        Requires specifying the model instance, the loss criterion to optimize,\n",
        "          the optimizer to use and the directory to save data to.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, criterion, optimizer):\n",
        "        \"\"\" Initializes the trainer.\n",
        "\n",
        "        Args:\n",
        "            directory (str): Directory to save checkpoints and the model data in.\n",
        "            model (torch.nn.Module): Torch model (must inherit `torch.nn.Module`) to train.\n",
        "            criterion (torch.nn.Function): Loss criterion, i.e., the loss function to optimize for training.\n",
        "            optimizer (torch.optim.Optimizer): Optimizer to use for training.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model            = model\n",
        "        self.optimizer        = optimizer\n",
        "        self.criterion        = criterion\n",
        "        self.last_checkpoint  = 0\n",
        "        self.loss_history     = { 'train': [], 'valid': [] }\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    def train_step(self, x_batch, y_batch):\n",
        "        \"\"\" Performs a step of training, on the training batch.\n",
        "\n",
        "        Args:\n",
        "            x_batch (torch.Tensor): Input batch.\n",
        "            y_batch (torch.Tensor): Output batch.\n",
        "\n",
        "        Returns:\n",
        "            float: Training loss with the current model, on this batch.\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        x_batch = x_batch.to(self.device)\n",
        "        y_batch = y_batch.to(self.device)\n",
        "        self.optimizer.zero_grad()\n",
        "        score,_ = self.model(x_batch,y_batch)\n",
        "        pred_size = score.size(2)\n",
        "        y_batch = y_batch[:,1:]\n",
        "        loss = self.criterion(score.view(-1,pred_size),y_batch.reshape(-1))\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def eval_step(self, validation_dataloader):\n",
        "        \"\"\" Perfoms an evaluation step, on the validation dataloader.\n",
        "\n",
        "        Args:\n",
        "            validation_dataloader (torch.utils.data.DataLoader): Dataloader for the validation dataset.\n",
        "\n",
        "        Returns:\n",
        "            float: Validation loss with the current model checkpoint.\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        val_loss = 0\n",
        "        for input, target in validation_dataloader:\n",
        "           input = input.to(self.device)\n",
        "           target = target.to(self.device)\n",
        "           score,_ = self.model(input,target)\n",
        "           pred_size = score.size(2)\n",
        "           target = target[:,1:]\n",
        "           loss = self.criterion(score.view(-1,pred_size),target.reshape(-1))\n",
        "           val_loss += loss.item()\n",
        "\n",
        "        evaluator1 = Evaluator()\n",
        "        evaluator1.set_decoding_method(rnn_greedy_generate)\n",
        "        evaluator1.evaluate( self.model,df_sample['English'], true_data)\n",
        "\n",
        "        return  val_loss/len(validation_dataloader)\n",
        "\n",
        "    def train(self, train_dataloader,  validation_dataloader =None,\n",
        "              num_epochs=10, batch_size=8, shuffle=True,\n",
        "              save_steps=100, eval_steps=100, collate_fn=None):\n",
        "        \"\"\" Handles the training loop for the model.\n",
        "\n",
        "        Args:\n",
        "            train_dataset (torch.utils.data.Dataset): Dataset to train on.\n",
        "            validation_dataset (torch.utils.data.Dataset, optional): Data to validate on. Defaults to None.\n",
        "            num_epochs (int, optional): Number of epochs to train for. Defaults to 10.\n",
        "            batch_size (int, optional): Number of items to process per batch. Defaults to 8.\n",
        "            shuffle (bool, optional): Whether to shuffle the data or not. Defaults to True.\n",
        "            save_steps (int, optional): Number of steps post which a checkpoint should be saved. Defaults to 100.\n",
        "            eval_steps (int, optional): Number of steps post which the model should be evaluated. Defaults to 100.\n",
        "            collate_fn (function, optional): Function to use for collating instances to a batch.\n",
        "        \"\"\"\n",
        "\n",
        "        current_checkpoint = 0\n",
        "        self.model.to(self.device)\n",
        "        self.model.train()\n",
        "        with tqdm.tqdm(total = math.ceil(len(train_dataset) / batch_size) * num_epochs) as pbar:\n",
        "            for epoch in range(num_epochs):\n",
        "                for batch, (x_batch, y_batch) in enumerate(train_dataloader):\n",
        "                    pbar.set_description(f\"Epoch {epoch+1} / {num_epochs}\")\n",
        "                    if current_checkpoint < self.last_checkpoint:\n",
        "                        current_checkpoint += 1\n",
        "                        pbar.update()\n",
        "                        continue\n",
        "                    loss = self.train_step(x_batch, y_batch)\n",
        "                    self.loss_history['train'].append(loss)\n",
        "                    pbar.set_postfix({ 'batch': batch+1, 'loss': loss })\n",
        "\n",
        "                    current_checkpoint += 1\n",
        "                    pbar.update()\n",
        "\n",
        "                    # Evaluate after every eval_steps\n",
        "                    if (current_checkpoint) % eval_steps == 0:\n",
        "                        if validation_dataset is not None:\n",
        "                            val_loss = self.eval_step(validation_dataloader)\n",
        "                            self.loss_history['valid'].append(val_loss)\n",
        "                        else:\n",
        "                            val_loss = None\n",
        "\n",
        "                        print('[>]', f\"epoch #{epoch+1:{len(str(num_epochs))}},\",\n",
        "                              f\"batch #{batch+1:{len(str(len(train_dataloader)))}}:\",\n",
        "                              \"loss:\", f\"{loss:.8f}\", '|', \"val_loss:\", f\"{val_loss:.8f}\")\n",
        "                    if (current_checkpoint) % save_steps == 0:\n",
        "                        self.save(current_checkpoint, { 'loss': loss, 'checkpoint': current_checkpoint })\n",
        "                    sync_vram()\n",
        "\n",
        "            self.save(current_checkpoint)\n",
        "\n",
        "\n",
        "    def save(self, checkpoint=None, metadata=None):\n",
        "        \"\"\" Saves an associated model or a training checkpoint.\n",
        "\n",
        "            If a checkpoint is specified, saves a checkpoint specific directory with optimizer data\n",
        "                so that training can be resumed post that checkpoint.\n",
        "\n",
        "        Args:\n",
        "            checkpoint (int, optional): Checkpoint index. Defaults to None.\n",
        "            metadata (dict[str, any], optional): Additional metadata to save alongside a checkpoint. Defaults to None.\n",
        "        \"\"\"\n",
        "        drive_path = '/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/'\n",
        "        if checkpoint is not None:\n",
        "            checkpoint_dir = drive_path + 'checkpoint/'#os.path.join(self.directory, f\"checkpoint-{checkpoint}\")\n",
        "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "            torch.save(self.model.state_dict(), os.path.join(checkpoint_dir, \"bidir_word_model.pt\"))\n",
        "            with open(os.path.join(checkpoint_dir, \"bidir_word_loss.json\"), \"w+\", encoding='utf-8') as ofile:\n",
        "                json.dump(self.loss_history, ofile, ensure_ascii=False, indent=2)\n",
        "\n",
        "        else:\n",
        "            directory = '/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/'\n",
        "            torch.save(self.model, os.path.join(directory, \"bidir_word_model.pt\"))\n",
        "            with open(os.path.join(directory, \"loss.json\"), \"w+\", encoding='utf-8') as ofile:\n",
        "                json.dump(self.loss_history, ofile, ensure_ascii=False, indent=2)\n",
        "            if metadata:\n",
        "                with open(os.path.join(directory, \"metadata.json\"), \"w+\", encoding='utf-8') as ofile:\n",
        "                    json.dump(metadata, ofile, ensure_ascii=False, indent=2)\n"
      ],
      "metadata": {
        "id": "dcjJCnrv3njc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add parameters related to the model here.\n",
        "rnn_enc_dec_attn_params = {\n",
        "    'src_vocab_size': len(eng_vocab),\n",
        "    'tgt_vocab_size': len(hin_vocab),\n",
        "    'embd_dims'     : 400,\n",
        "    'hidden_size'   : 800,\n",
        "    'dropout'       : 0.3,\n",
        "    'num_layers'    : 4,\n",
        "    'teacher_force_ratio' : 0.6\n",
        "}\n",
        "\n",
        "rnn_enc_dec_attn_training_params = dict(\n",
        "    num_epochs=15,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    save_steps=500,\n",
        "    eval_steps= 500\n",
        ")\n",
        "torch.manual_seed(42)\n",
        "model = RNNEncoderDecoderLMWithAttention(**rnn_enc_dec_attn_params)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)\n",
        "learning_rate = 0.001\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.NLLLoss()\n",
        "trainer = Trainer(\n",
        "    model, criterion, optimizer\n",
        ")"
      ],
      "metadata": {
        "id": "1hKS2woH3nmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset      = train_dataloader\n",
        "validation_dataset = valid_dataloader\n",
        "\n",
        "rnn_enc_dec_attn_train_data = dict(\n",
        "    train_dataset=train_dataset,\n",
        "    validation_dataset=validation_dataset,\n",
        ")\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "trainer.train(train_dataloader,valid_dataloader, **rnn_enc_dec_attn_training_params)"
      ],
      "metadata": {
        "id": "BdiDgEnv3nsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_enc_dec_attn_params = {\n",
        "    'src_vocab_size': len(eng_vocab),\n",
        "    'tgt_vocab_size': len(eng_vocab),\n",
        "    'embd_dims'     : 400,\n",
        "    'hidden_size'   : 800,\n",
        "    'dropout'       : 0.3,\n",
        "    'num_layers'    : 4,\n",
        "    'teacher_force_ratio' : 0.8\n",
        "}\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_path = '/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/bidir_word_model.pt'\n",
        "model_state_dict = torch.load(model_path, map_location = device)\n",
        "\n",
        "model_uni = RNNEncoderDecoderLMWithAttention(**rnn_enc_dec_attn_params)\n",
        "model_uni.load_state_dict(model_state_dict)\n",
        "model_uni = model_uni.to(device)"
      ],
      "metadata": {
        "id": "6ulEdsqUELaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = Evaluator()\n",
        "evaluator.set_decoding_method(rnn_greedy_generate)\n",
        "evaluator.evaluate(\n",
        "    model_uni,\n",
        "    df_sample['English'], true_data\n",
        ")"
      ],
      "metadata": {
        "id": "iwGEBgvtEP0h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}