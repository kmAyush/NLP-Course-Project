{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmAyush/Video-Dubbing-with-Lip-Synchronization/blob/main/Text%20Translation/BPE_BiDirectional_Trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t80CFLWF4c2m",
        "outputId": "d6070ff3-c82e-45fc-f222-42ec5d484b48"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "dTx56L38_mIR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import  nltk.translate.bleu_score as bleu\n",
        "\n",
        "from io import open\n",
        "import unicodedata\n",
        "import random\n",
        "import tqdm.auto as tqdm\n",
        "\n",
        "from nltk.translate import bleu_score\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import json\n",
        "import os\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://drive.google.com/file/d/1-7s8Kqr205fJQgl1m8Z36L3cykv0GKJG/view?usp=sharing\"\n",
        "id = url.split('/')[-2]\n",
        "file_url = f'https://drive.google.com/uc?id={id}'\n",
        "destination_location = \"/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/BPE/\"\n",
        "gdown.download(file_url , destination_location, quiet=False )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "rE2Pv7EuuHIZ",
        "outputId": "264a2e3c-1783-4983-871b-c05cff5d4d78"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-7s8Kqr205fJQgl1m8Z36L3cykv0GKJG\n",
            "To: /content/Video-Dubbing-with-Lip-Synchronization/Text Translation/BPE/english.pkl\n",
            "100%|██████████| 7.23M/7.23M [00:00<00:00, 168MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/BPE/english.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://drive.google.com/file/d/1-OjFAj8qMQnT_WNfq9mvkUguGuJogDVv/view?usp=sharing\"\n",
        "id = url.split('/')[-2]\n",
        "file_url = f'https://drive.google.com/uc?id={id}'\n",
        "destination_location = \"/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/BPE/\"\n",
        "gdown.download(file_url , destination_location, quiet=False )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Jrnr9ONP_C7W",
        "outputId": "c4f7ef77-f505-461f-a062-34641e9baefe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-OjFAj8qMQnT_WNfq9mvkUguGuJogDVv\n",
            "To: /content/Video-Dubbing-with-Lip-Synchronization/Text Translation/BPE/hindi.pkl\n",
            "100%|██████████| 15.0M/15.0M [00:00<00:00, 137MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/BPE/hindi.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://drive.google.com/file/d/1ZjhBUE0w-SB6kO9_GFrrRIqCzKzGtQHC/view?usp=sharing\"\n",
        "\n",
        "id = url.split('/')[-2]\n",
        "file_url = f'https://drive.google.com/uc?id={id}'\n",
        "destination_location = \"/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/\"\n",
        "gdown.download(file_url , destination_location, quiet=False )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "0u0Gzm0guk5X",
        "outputId": "a1c883a4-2ab1-4659-b2a6-66cbe9f96b5d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZjhBUE0w-SB6kO9_GFrrRIqCzKzGtQHC\n",
            "To: /content/Video-Dubbing-with-Lip-Synchronization/Text Translation/new_data.csv\n",
            "100%|██████████| 7.62M/7.62M [00:00<00:00, 65.8MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/new_data.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file into a DataFrame\n",
        "file_path = \"/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/new_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "df = df.iloc[:,:2]\n",
        "df = df.dropna()\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tsz4ajpzAwpZ",
        "outputId": "7d0668ba-a883-428b-a315-a8f59a49bbfa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0                (LAUGHS) Oh, you're getting a bill.   \n",
              "1                                Welcome, Professor.   \n",
              "2      PROFESSOR X: Are we\\ndestined down this path?   \n",
              "3  We are at site coordinates\\napproximately 15H-...   \n",
              "4                                     What was that?   \n",
              "\n",
              "                                          Hindi  \n",
              "0          (हंसते हुए) ओह, आपको बिल मिल रहा है।  \n",
              "1                     आपका स्वागत है, प्रोफेसर.  \n",
              "2  प्रोफेसर एक्स: क्या हम हैं?\\nइस पथ पर नियति?  \n",
              "3    हम साइट निर्देशांक पर हैं\\nलगभग 15एच-32...  \n",
              "4                                   वह क्या था?  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3990f813-ed45-4915-88cc-34712aa240fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(LAUGHS) Oh, you're getting a bill.</td>\n",
              "      <td>(हंसते हुए) ओह, आपको बिल मिल रहा है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Welcome, Professor.</td>\n",
              "      <td>आपका स्वागत है, प्रोफेसर.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PROFESSOR X: Are we\\ndestined down this path?</td>\n",
              "      <td>प्रोफेसर एक्स: क्या हम हैं?\\nइस पथ पर नियति?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We are at site coordinates\\napproximately 15H-...</td>\n",
              "      <td>हम साइट निर्देशांक पर हैं\\nलगभग 15एच-32...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What was that?</td>\n",
              "      <td>वह क्या था?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3990f813-ed45-4915-88cc-34712aa240fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3990f813-ed45-4915-88cc-34712aa240fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3990f813-ed45-4915-88cc-34712aa240fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd101224-6903-4b9b-b081-e0b9fe78e5f3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd101224-6903-4b9b-b081-e0b9fe78e5f3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd101224-6903-4b9b-b081-e0b9fe78e5f3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 60007,\n  \"fields\": [\n    {\n      \"column\": \"English\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56770,\n        \"samples\": [\n          \"Bring your mask if you want.\\nI'm getting used to it.\",\n          \"Surrendering my father's ship\\nwill not guarantee survival, Mr. Phelps.\",\n          \"You always do.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hindi\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 55963,\n        \"samples\": [\n          \"\\u0905\\u0930\\u0947! \\u0906\\u092a \\u0915\\u094d\\u092f\\u093e \\u0915\\u0930 \\u0930\\u0939\\u0947 \\u0939\\u094b?\",\n          \"\\u091c\\u0948\\u0938\\u093e \\u0915\\u093f \\u0906\\u092a\\u0915\\u093e \\u0939\\u0948.\",\n          \"\\u0906\\u0913, \\u090f\\u0921\\u0940. \\u0924\\u0941\\u092e \\u092e\\u0947\\u0930\\u0947 \\u0939\\u0940 \\u0909\\u092e\\u094d\\u092e\\u0940\\u0926 \\u0915\\u0930 \\u0930\\u0939\\u0947 \\u0939\\u0948\\u0902\\u0964\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "UeqFzq0JeSxK"
      },
      "outputs": [],
      "source": [
        "class Tokenizer:\n",
        "    \"\"\" Represents the tokenizer for text data.\n",
        "        Provides methods to encode and decode strings (as instance or as a batch). \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\" Initializes a new tokenizer.\n",
        "\n",
        "            Any variables required in intermediate operations are declared here.\n",
        "            You will also need to define things like special tokens and other things here.\n",
        "\n",
        "            All variables declared in this function will be serialized\n",
        "                and deserialized when loading and saving the Tokenizer.\n",
        "            \"\"\"\n",
        "        self.pad_t = '<pad>'\n",
        "        self.unk = '<unk>'\n",
        "        self.start = '<start>'\n",
        "        self.end = '<end>'\n",
        "        self.vocab = {}\n",
        "        self.tokens = []\n",
        "        self.ids = []\n",
        "        self.merges = {}\n",
        "        self.vocab_size = None\n",
        "        self.num_merges = None\n",
        "        self.end_token_number = None\n",
        "        self.pad_token_number = None\n",
        "    @classmethod\n",
        "    def load(cls, path):\n",
        "        \"\"\" Loads a pre-trained tokenizer from the given directory.\n",
        "           This directory will have a tokenizer.pkl file that contains all the tokenizer variables.\n",
        "\n",
        "        Args:\n",
        "            path (str): Path to load the tokenizer from.\n",
        "        \"\"\"\n",
        "        tokenizer_file = os.path.join(path, \"tokenizer.pkl\")\n",
        "\n",
        "        if not os.path.exists(path) or not os.path.exists(os.path.join(path, \"tokenizer.pkl\")):\n",
        "            raise ValueError(cls.load.__name__ + \": No tokenizer found at the specified directory\")\n",
        "\n",
        "        with open(tokenizer_file, \"rb\") as ifile:\n",
        "            return pickle.load(ifile)\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\" Saves a trained tokenizer to a given directory, inside a tokenizer.pkl file.\n",
        "\n",
        "        Args:\n",
        "            path (str): Directory to save the tokenizer in.\n",
        "        \"\"\"\n",
        "\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        with open(os.path.join(path, \"tokenizer.pkl\"), 'wb') as ofile:\n",
        "            pickle.dump(self, ofile)\n",
        "\n",
        "    def get_stats(self, ids):\n",
        "      counts = {}\n",
        "      for pair in zip(ids, ids[1:]):\n",
        "        if pair[0] != self.end_token_number and pair[1] != self.end_token_number:\n",
        "            counts[pair] = counts.get(pair, 0) + 1\n",
        "      return counts\n",
        "\n",
        "    def merge(self, ids, pair, idx):\n",
        "      newids = []\n",
        "      i = 0\n",
        "      while i < len(ids):\n",
        "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
        "          newids.append(idx)\n",
        "          i += 2\n",
        "        else:\n",
        "          newids.append(ids[i])\n",
        "          i += 1\n",
        "\n",
        "      return newids\n",
        "\n",
        "    def train(self, data, vocab_size):\n",
        "        \"\"\" Trains a tokenizer to learn meaningful representations from input data.\n",
        "            In the end, learns a vocabulary of a fixed size over the given data.\n",
        "            Special tokens, if any, must not be counted towards this vocabulary.\n",
        "\n",
        "        Args:\n",
        "            data (list[str]): List of input strings from a text corpus.\n",
        "            vocab_size (int): Final desired size of the vocab to be learnt.\n",
        "        \"\"\"\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_merges = vocab_size - 256 - 3\n",
        "        self.start_token_number = vocab_size - 3\n",
        "        self.end_token_number = vocab_size - 2\n",
        "        self.pad_token_number = vocab_size - 1\n",
        "\n",
        "        for name in data:\n",
        "          temp_tokens = name.encode('utf-8')\n",
        "          temp_tokens = list(map(int, temp_tokens))\n",
        "          temp_tokens.append(self.end_token_number)\n",
        "          self.tokens += temp_tokens\n",
        "\n",
        "        self.ids = list(self.tokens)\n",
        "        for i in range(self.num_merges):\n",
        "          stats = self.get_stats(self.ids)\n",
        "          pair = max(stats, key = stats.get)\n",
        "          idx = 256 + i\n",
        "          self.ids = self.merge(self.ids,pair, idx)\n",
        "          self.merges[pair] = idx\n",
        "\n",
        "\n",
        "    def pad(self, tokens, length):\n",
        "        \"\"\" Pads a tokenized string to a specified length, for batch processing.\n",
        "\n",
        "        Args:\n",
        "            tokens (list[int]): Encoded token string to be padded.\n",
        "            length (int): Length of tokens to pad to.\n",
        "\n",
        "        Returns:\n",
        "            list[int]: Token string padded to desired length.\n",
        "        \"\"\"\n",
        "        special_tokens = self.get_special_tokens()\n",
        "        pad_val = special_tokens[self.pad_t]\n",
        "        while len(tokens) < length:\n",
        "             tokens.append(pad_val)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def unpad(self, tokens):\n",
        "        \"\"\" Removes padding from a token string.\n",
        "\n",
        "        Args:\n",
        "            tokens (list[int]): Encoded token string with padding.\n",
        "\n",
        "        Returns:\n",
        "            list[int]: Token string with padding removed.\n",
        "        \"\"\"\n",
        "        special_tokens = self.get_special_tokens()\n",
        "        pad_val = special_tokens[self.pad_t]\n",
        "        while tokens[-1] == pad_val:\n",
        "           tokens.pop()\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def get_special_tokens(self):\n",
        "        \"\"\" Returns the associated special tokens.\n",
        "\n",
        "            Returns:\n",
        "                dict[str, int]: Mapping describing the special tokens, if any.\n",
        "                    This is a mapping between a string segment (token) and its associated id (token_id).\n",
        "        \"\"\"\n",
        "        special_tokens = {self.end:self.end_token_number, self.pad_t : self.pad_token_number, self.start : self.start_token_number }\n",
        "        return special_tokens\n",
        "\n",
        "\n",
        "    def get_vocabulary(self):\n",
        "        \"\"\" Returns the learnt vocabulary post the training process.\n",
        "\n",
        "            Returns:\n",
        "                dict[str, int]: Mapping describing the vocabulary and special tokens, if any.\n",
        "                    This is a mapping between a string segment (token) and its associated id (token_id).\n",
        "        \"\"\"\n",
        "        self.vocab = {idx: bytes([idx]) for idx in range(256)} # dict  of token id and\n",
        "        special_tokens = self.get_special_tokens()\n",
        "        vc = {v:k.encode('utf-8') for k,v in special_tokens.items()}\n",
        "        self.vocab.update(vc)\n",
        "        for (p0, p1), idx in self.merges.items():\n",
        "            self.vocab[idx] = self.vocab[p0] + self.vocab[p1]\n",
        "\n",
        "        temp_vocab = {val:key for key,val in self.vocab.items()}\n",
        "        return temp_vocab\n",
        "\n",
        "\n",
        "    def encode(self, string, add_start=True, add_end=True):\n",
        "        \"\"\" Encodes a string into a list of tokens.\n",
        "\n",
        "        Args:\n",
        "            string (str): Input string to be tokenized.\n",
        "            add_start (bool): If true, adds the start of sequence token.\n",
        "            add_end (bool): If true, adds the end of sequence token.\n",
        "        Returns:\n",
        "            list[int]: List of tokens (unpadded).\n",
        "        \"\"\"\n",
        "        tokens = []\n",
        "        if add_start == True:\n",
        "          tokens.append(self.start_token_number)\n",
        "\n",
        "        tokens.extend(list(string.encode(\"utf-8\")))\n",
        "\n",
        "        if add_end  == True:\n",
        "           tokens.append(self.end_token_number)\n",
        "        while len(tokens) >= 2:\n",
        "          stats = self.get_stats(tokens)\n",
        "          pair = min(stats, key=lambda p: self.merges.get(p, float(\"inf\")))\n",
        "          if pair not in self.merges:\n",
        "              break\n",
        "          idx = self.merges[pair]\n",
        "          tokens = self.merge(tokens, pair, idx)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def decode(self, tokens, strip_special=True):\n",
        "        \"\"\" Decodes a string from a list of tokens.\n",
        "            Undoes the tokenization, returning back the input string.\n",
        "\n",
        "        Args:\n",
        "            tokens (list[int]): List of encoded tokens to be decoded. No padding is assumed.\n",
        "            strip_special (bool): Whether to remove special tokens or not.\n",
        "\n",
        "        Returns:\n",
        "            str: Decoded string.\n",
        "        \"\"\"\n",
        "        end_length = len(self.end)\n",
        "        if strip_special:\n",
        "            if tokens[0] == self.start_token_number:\n",
        "                tokens = tokens[1:]\n",
        "        t_text = b\"\".join(self.vocab[idx] for idx in tokens)\n",
        "        text = t_text.decode(\"utf-8\", errors=\"replace\")\n",
        "\n",
        "        if text.endswith(self.end):\n",
        "          text = text[:-end_length]\n",
        "\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "WfmDxVWSepiY"
      },
      "outputs": [],
      "source": [
        "def render_glyph(token):\n",
        "    \"\"\" Renders a token, handling invalid bytes in a safe, error-proof manner. \"\"\"\n",
        "\n",
        "    token = token.decode('utf-8', errors='replace') if isinstance(token, bytes) else token\n",
        "    return \"\".join([ c if unicodedata.category(c)[0] != \"C\" else f\"\\\\u{ord(c):04x}\" for c in token ])\n",
        "\n",
        "def inverse_vocabulary(tokenizer):\n",
        "    \"\"\" Generates an inverse vocabulary with rendered tokens.\n",
        "\n",
        "    Args:\n",
        "        tokenizer (Tokenizer): Tokenizer whose vocabulary must be used.\n",
        "    \"\"\"\n",
        "\n",
        "    return { id: render_glyph(token) for token, id in tokenizer.get_vocabulary().items() }\n",
        "\n",
        "def apply_inverse_vocab(tokens, inv_vocab):\n",
        "    \"\"\" Decodes using the given inverse vocabulary.\n",
        "\n",
        "    Args:\n",
        "        tokens (list[int]): Tokens to process.\n",
        "        inv_vocab (dict[int, str]): Inverse vocabulary for mapping ids to tokens.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: Mapped token glyphs.\n",
        "    \"\"\"\n",
        "\n",
        "    return [ inv_vocab[id] for id in tokens ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "NBgx7PFseS9x"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/BPE/english.pkl'\n",
        "\n",
        "with open(file_path, 'rb') as file:\n",
        "    src_tokenizer_model = pickle.load(file)\n",
        "\n",
        "file_path = '/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/BPE/hindi.pkl'\n",
        "\n",
        "with open(file_path, 'rb') as file:\n",
        "    tgt_tokenizer_model = pickle.load(file)\n",
        "\n",
        "eng_vocab = src_tokenizer_model.get_vocabulary()\n",
        "hin_vocab = tgt_tokenizer_model.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "1Ddr8AB2QHSV"
      },
      "outputs": [],
      "source": [
        "pairs = [[ src_tokenizer_model.encode(row['English']) , tgt_tokenizer_model.encode(row['Hindi']) ] for index, row in df.iterrows()]\n",
        "from sklearn.model_selection import train_test_split\n",
        "pairs_train, pairs_rest = train_test_split(pairs, test_size=0.2, random_state=42)\n",
        "pairs_valid, pairs_test = train_test_split(pairs_rest, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "wfab2kgueTF7"
      },
      "outputs": [],
      "source": [
        "df_test = pd.DataFrame(pairs_test,columns = ['English','Hindi'])\n",
        "df_train = pd.DataFrame(pairs_train,columns = ['English','Hindi'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "833ugnM4QHVV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, pairs):\n",
        "        self.pairs = pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_data, target_data = self.pairs[idx]\n",
        "\n",
        "        return torch.tensor(input_data), torch.tensor(target_data)\n",
        "\n",
        "def pad_collate(batch):\n",
        "    input_seqs, target_seqs = zip(*batch)\n",
        "\n",
        "    input_seqs_padded = torch.nn.utils.rnn.pad_sequence(input_seqs, batch_first=True)\n",
        "\n",
        "    # Pad target sequences to the maximum length in the batch\n",
        "    target_seqs_padded = torch.nn.utils.rnn.pad_sequence(target_seqs, batch_first=True)\n",
        "\n",
        "    return input_seqs_padded, target_seqs_padded\n",
        "\n",
        "\n",
        "dataset_tr = MyDataset(pairs_train)\n",
        "dataset_val = MyDataset(pairs_valid)\n",
        "dataset_te = MyDataset(pairs_test)\n",
        "\n",
        "batch_size = 8\n",
        "train_dataloader = DataLoader(dataset_tr, batch_size=batch_size, collate_fn=pad_collate)\n",
        "test_dataloader = DataLoader(dataset_te, batch_size=batch_size, collate_fn=pad_collate)\n",
        "valid_dataloader = DataLoader(dataset_val, batch_size=batch_size, collate_fn=pad_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Wn7x2ed83ncs"
      },
      "outputs": [],
      "source": [
        "class AttentionModule(torch.nn.Module):\n",
        "    \"\"\" Implements an attention module \"\"\"\n",
        "\n",
        "    # Feel free to add additional parameters to __init__\n",
        "    def __init__(self, input_size):\n",
        "        \"\"\" Initializes the attention module.\n",
        "            Feel free to declare any parameters as required. \"\"\"\n",
        "\n",
        "        super(AttentionModule, self).__init__()\n",
        "\n",
        "        # BEGIN CODE : attn.init\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        self.W_key = nn.Linear((2*input_size), input_size)\n",
        "        self.W_query = nn.Linear(input_size, input_size)\n",
        "        self.W_value =nn.Linear((2*input_size), input_size)\n",
        "\n",
        "\n",
        "        # END CODE\n",
        "\n",
        "    def forward(self, encoder_outputs, decoder_hidden_state):\n",
        "        \"\"\" Performs a forward pass over the module, computing attention scores for inputs.\n",
        "\n",
        "        Args:\n",
        "            encoder_outputs (torch.Tensor): Output representations from the encoder, of shape [batch_size?, src_seq_len, output_dim].\n",
        "            decoder_hidden_state (torch.Tensor): Hidden state from the decoder at current time step, of appropriate shape as per RNN unit (with optional batch dim).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Attentions scores for given inputs, of shape [batch_size?, 1, src_seq_len]\n",
        "        \"\"\"\n",
        "\n",
        "        keys = self.W_key(encoder_outputs)  # batch,seq_length, hidden_size\n",
        "        values = self.W_value(encoder_outputs)   # batch,seq_length, hidden_size\n",
        "\n",
        "        # decoder_hidden_state ==  num_layer,N, hid_size\n",
        "\n",
        "        num_layers = decoder_hidden_state.size(0)\n",
        "        decoder_hidden_state = decoder_hidden_state[num_layers-1].unsqueeze(1)  # N , 1, hidden\n",
        "        query = self.W_query(decoder_hidden_state)  #  batch,1 ,hidden_size\n",
        "        query = query.transpose(1, 2)  # (batch size, hidden size, 1)\n",
        "\n",
        "        weights = torch.matmul(keys, query)  # batch , sequence, 1\n",
        "        weights = F.softmax(weights, dim = 1)   # (batch, sequence,  1)\n",
        "\n",
        "        context_vector = weights * values  # N, seq_length , hidden\n",
        "\n",
        "        context_vector = torch.sum(context_vector, dim = 1, keepdim = True) # N, 1, hidden\n",
        "\n",
        "        return context_vector, weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "4bzPhPFA3ngF"
      },
      "outputs": [],
      "source": [
        "class RNNEncoderDecoderLMWithAttention(torch.nn.Module):\n",
        "    \"\"\" Implements an Encoder-Decoder network, using RNN units, augmented with attention. \"\"\"\n",
        "    def __init__(self,src_vocab_size, tgt_vocab_size, embd_dims, hidden_size, num_layers=1, dropout=0.1, teacher_force_ratio = 1 ):\n",
        "        \"\"\" Initializes the encoder-decoder network, implemented via RNNs.\n",
        "\n",
        "        Args:\n",
        "            src_vocab_size (int): Source vocabulary size.\n",
        "            tgt_vocab_size (int): Target vocabulary size.\n",
        "            embd_dims (int): Embedding dimensions.\n",
        "            hidden_size (int): Size/Dimensions for the hidden states.\n",
        "        \"\"\"\n",
        "\n",
        "        super(RNNEncoderDecoderLMWithAttention, self).__init__()\n",
        "\n",
        "        # Dummy parameter to track the model device. Do not modify.\n",
        "        self._dummy_param = torch.nn.Parameter(torch.Tensor(0), requires_grad=False)\n",
        "\n",
        "        self.src_vocab_size = src_vocab_size\n",
        "        self.tgt_vocab_size = tgt_vocab_size\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.dropout_enc = nn.Dropout(dropout)\n",
        "        self.dropout_dec = nn.Dropout(dropout)\n",
        "        self.teacher_force_ratio = teacher_force_ratio\n",
        "        self.enc_pad_index = src_vocab_size - 1\n",
        "\n",
        "        self.tgt_pad_index = tgt_vocab_size -1\n",
        "        self.tgt_start_index = tgt_vocab_size - 3\n",
        "        self.tgt_end_index = tgt_vocab_size - 2\n",
        "\n",
        "        self.attension_module = AttentionModule(hidden_size)\n",
        "\n",
        "        self.encoder_embedding = torch.nn.Embedding(src_vocab_size, embd_dims)\n",
        "        self.encoder_lstm = nn.LSTM(embd_dims, hidden_size,num_layers = num_layers , batch_first = True, dropout = dropout, bidirectional=True)\n",
        "\n",
        "        self.decoder_embedding = torch.nn.Embedding(tgt_vocab_size, embd_dims)\n",
        "        self.decoder_lstm = nn.LSTM(embd_dims+hidden_size, hidden_size,num_layers = num_layers, batch_first = True, dropout = dropout)\n",
        "        self.decoder_output_fc = nn.Linear(hidden_size, embd_dims)\n",
        "        self.dec_out_embed = nn.Linear(embd_dims,tgt_vocab_size, bias = False)\n",
        "\n",
        "        self.dec_out_embed.weight = self.decoder_embedding.weight\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        return self._dummy_param.device\n",
        "\n",
        "    def forward(self, inputs, decoder_inputs=None, decoder_hidden_state=None, output_attention=False ):\n",
        "        \"\"\" Performs a forward pass over the encoder-decoder network.\n",
        "\n",
        "            Accepts inputs for the encoder, inputs for the decoder, and hidden state for\n",
        "                the decoder to continue generation after the given input.\n",
        "\n",
        "        Args:\n",
        "            inputs (torch.Tensor): tensor of shape [batch_size?, src_seq_len]\n",
        "            decoder_inputs (torch.Tensor): Decoder inputs, as tensor of shape [batch_size?, 1]\n",
        "            decoder_hidden_state (any): tensor to represent decoder hidden state from time step T-1.\n",
        "            output_attention (bool): If true, this function should also return the\n",
        "                associated attention weights for the time step, of shape [batch_size?, 1, src_seq_len].\n",
        "\n",
        "        Returns:\n",
        "            tuple[torch.Tensor, any]: output from the decoder, and associated hidden state for the next step.\n",
        "\n",
        "            Decoder outputs should be log probabilities over the target vocabulary.\n",
        "\n",
        "        Example:\n",
        "        >>> model = RNNEncoderDecoderWithAttention(*args, **kwargs)\n",
        "        >>> output, hidden = model(..., output_attention=False)\n",
        "        >>> output, hidden, attn_weights = model(..., output_attention=True)\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = inputs.size(0)\n",
        "        seq_length = decoder_inputs.size(1) if decoder_inputs != None else inputs.size(1)\n",
        "        encoder_input_embed = self.encoder_embedding(inputs)\n",
        "        encoder_output, (encoder_hidden ,cell_encoder )= self.encoder_lstm(encoder_input_embed)\n",
        "\n",
        "        decoder_hidden = encoder_hidden[:self.num_layers,:,:]\n",
        "        decoder_cell = cell_encoder[:self.num_layers,:,:]\n",
        "        decoder_input_test = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(self.tgt_start_index)\n",
        "\n",
        "\n",
        "        pred_output_prob = []\n",
        "        weights  = []\n",
        "        for i in range(1,seq_length):\n",
        "\n",
        "            decoder_input_embed = self.decoder_embedding(decoder_input_test)\n",
        "            context_vector, wts = self.attension_module(encoder_output, decoder_hidden)  #in biderectional lstm out sieze(N,SEQ,2*HIDD)\n",
        "            decoder_input_lstm = torch.cat((decoder_input_embed, context_vector), dim = 2)\n",
        "\n",
        "            dec_output, (decoder_hidden,decoder_cell) = self.decoder_lstm(decoder_input_lstm, (decoder_hidden,decoder_cell))\n",
        "            out_tgt = self.decoder_output_fc(dec_output)\n",
        "            out_tgt_embd = self.dec_out_embed(out_tgt)\n",
        "            pred_output = F.log_softmax(out_tgt_embd, dim = -1)\n",
        "\n",
        "            if decoder_inputs != None:\n",
        "              teacher_frc = torch.rand(1, 1)\n",
        "              if teacher_frc < self.teacher_force_ratio:\n",
        "                 decoder_input_test = decoder_inputs[:, i].unsqueeze(1)\n",
        "\n",
        "              else:\n",
        "                 _, topi = pred_output.topk(1)\n",
        "                 decoder_input_test = topi.squeeze(-1).detach()\n",
        "            else:\n",
        "               _, topi = pred_output.topk(1)\n",
        "               decoder_input_test = topi.squeeze(-1).detach()\n",
        "\n",
        "            pred_output_prob.append(pred_output)\n",
        "            wts = wts.squeeze(0).squeeze(1)\n",
        "            weights.append(wts)\n",
        "\n",
        "\n",
        "        pred_output_prob = torch.cat(pred_output_prob, dim = 1)\n",
        "        weights = torch.stack(weights)\n",
        "\n",
        "\n",
        "        return pred_output_prob,weights  #, decoder_hidden, decoder_cell , encoder_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "wTzDvPyO7sCK"
      },
      "outputs": [],
      "source": [
        "def sync_vram():\n",
        "    \"\"\" Synchronizes the VRAM across the GPUs, reclaiming unused memory. \"\"\"\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.synchronize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "dcjJCnrv3njc"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    \"\"\" Performs model training in a model-agnostic manner.\n",
        "        Requires specifying the model instance, the loss criterion to optimize,\n",
        "          the optimizer to use and the directory to save data to.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, criterion, optimizer):\n",
        "        \"\"\" Initializes the trainer.\n",
        "\n",
        "        Args:\n",
        "            directory (str): Directory to save checkpoints and the model data in.\n",
        "            model (torch.nn.Module): Torch model (must inherit `torch.nn.Module`) to train.\n",
        "            criterion (torch.nn.Function): Loss criterion, i.e., the loss function to optimize for training.\n",
        "            optimizer (torch.optim.Optimizer): Optimizer to use for training.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model            = model\n",
        "        self.optimizer        = optimizer\n",
        "        self.criterion        = criterion\n",
        "        self.last_checkpoint  = 0\n",
        "        self.loss_history     = { 'train': [], 'valid': [] }\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    def train_step(self, x_batch, y_batch):\n",
        "        \"\"\" Performs a step of training, on the training batch.\n",
        "\n",
        "        Args:\n",
        "            x_batch (torch.Tensor): Input batch.\n",
        "            y_batch (torch.Tensor): Output batch.\n",
        "\n",
        "        Returns:\n",
        "            float: Training loss with the current model, on this batch.\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        x_batch = x_batch.to(self.device)\n",
        "        y_batch = y_batch.to(self.device)\n",
        "        self.optimizer.zero_grad()\n",
        "        score,_ = self.model(x_batch,y_batch)\n",
        "        pred_size = score.size(2)\n",
        "        y_batch = y_batch[:,1:]\n",
        "        loss = self.criterion(score.view(-1,pred_size),y_batch.reshape(-1))\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def eval_step(self, validation_dataloader):\n",
        "        \"\"\" Perfoms an evaluation step, on the validation dataloader.\n",
        "\n",
        "        Args:\n",
        "            validation_dataloader (torch.utils.data.DataLoader): Dataloader for the validation dataset.\n",
        "\n",
        "        Returns:\n",
        "            float: Validation loss with the current model checkpoint.\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        val_loss = 0\n",
        "        for input, target in validation_dataloader:\n",
        "           input = input.to(self.device)\n",
        "           target = target.to(self.device)\n",
        "           score,_ = self.model(input,target)\n",
        "           pred_size = score.size(2)\n",
        "           target = target[:,1:]\n",
        "           loss = self.criterion(score.view(-1,pred_size),target.reshape(-1))\n",
        "           val_loss += loss.item()\n",
        "\n",
        "        evaluator1 = Evaluator()\n",
        "        evaluator1.set_decoding_method(rnn_greedy_generate)\n",
        "        evaluator1.evaluate( self.model,df_sample['English'], true_data)\n",
        "\n",
        "        return  val_loss/len(validation_dataloader)\n",
        "\n",
        "    def train(self, train_dataloader,  validation_dataloader =None,\n",
        "              num_epochs=10, batch_size=8, shuffle=True,\n",
        "              save_steps=100, eval_steps=100, collate_fn=None):\n",
        "        \"\"\" Handles the training loop for the model.\n",
        "\n",
        "        Args:\n",
        "            train_dataset (torch.utils.data.Dataset): Dataset to train on.\n",
        "            validation_dataset (torch.utils.data.Dataset, optional): Data to validate on. Defaults to None.\n",
        "            num_epochs (int, optional): Number of epochs to train for. Defaults to 10.\n",
        "            batch_size (int, optional): Number of items to process per batch. Defaults to 8.\n",
        "            shuffle (bool, optional): Whether to shuffle the data or not. Defaults to True.\n",
        "            save_steps (int, optional): Number of steps post which a checkpoint should be saved. Defaults to 100.\n",
        "            eval_steps (int, optional): Number of steps post which the model should be evaluated. Defaults to 100.\n",
        "            collate_fn (function, optional): Function to use for collating instances to a batch.\n",
        "        \"\"\"\n",
        "\n",
        "        current_checkpoint = 0\n",
        "        self.model.to(self.device)\n",
        "        self.model.train()\n",
        "        with tqdm.tqdm(total = math.ceil(len(train_dataset) / batch_size) * num_epochs) as pbar:\n",
        "            for epoch in range(num_epochs):\n",
        "                for batch, (x_batch, y_batch) in enumerate(train_dataloader):\n",
        "                    pbar.set_description(f\"Epoch {epoch+1} / {num_epochs}\")\n",
        "                    if current_checkpoint < self.last_checkpoint:\n",
        "                        current_checkpoint += 1\n",
        "                        pbar.update()\n",
        "                        continue\n",
        "                    loss = self.train_step(x_batch, y_batch)\n",
        "                    self.loss_history['train'].append(loss)\n",
        "                    pbar.set_postfix({ 'batch': batch+1, 'loss': loss })\n",
        "\n",
        "                    current_checkpoint += 1\n",
        "                    pbar.update()\n",
        "\n",
        "                    # Evaluate after every eval_steps\n",
        "                    if (current_checkpoint) % eval_steps == 0:\n",
        "                        if validation_dataset is not None:\n",
        "                            val_loss = self.eval_step(validation_dataloader)\n",
        "                            self.loss_history['valid'].append(val_loss)\n",
        "                        else:\n",
        "                            val_loss = None\n",
        "\n",
        "                        print('[>]', f\"epoch #{epoch+1:{len(str(num_epochs))}},\",\n",
        "                              f\"batch #{batch+1:{len(str(len(train_dataloader)))}}:\",\n",
        "                              \"loss:\", f\"{loss:.8f}\", '|', \"val_loss:\", f\"{val_loss:.8f}\")\n",
        "                    if (current_checkpoint) % save_steps == 0:\n",
        "                        self.save(current_checkpoint, { 'loss': loss, 'checkpoint': current_checkpoint })\n",
        "                    sync_vram()\n",
        "\n",
        "            self.save(current_checkpoint)\n",
        "\n",
        "\n",
        "    def save(self, checkpoint=None, metadata=None):\n",
        "        \"\"\" Saves an associated model or a training checkpoint.\n",
        "\n",
        "            If a checkpoint is specified, saves a checkpoint specific directory with optimizer data\n",
        "                so that training can be resumed post that checkpoint.\n",
        "\n",
        "        Args:\n",
        "            checkpoint (int, optional): Checkpoint index. Defaults to None.\n",
        "            metadata (dict[str, any], optional): Additional metadata to save alongside a checkpoint. Defaults to None.\n",
        "        \"\"\"\n",
        "        drive_path = '/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/BPE/'\n",
        "        if checkpoint is not None:\n",
        "            checkpoint_dir = drive_path + 'checkpoint/'#os.path.join(self.directory, f\"checkpoint-{checkpoint}\")\n",
        "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "            torch.save(self.model.state_dict(), os.path.join(checkpoint_dir, \"model.pt\"))\n",
        "            torch.save(self.optimizer.state_dict(), os.path.join(checkpoint_dir, \"optimizer.pt\"))\n",
        "            with open(os.path.join(checkpoint_dir, \"loss.json\"), \"w+\", encoding='utf-8') as ofile:\n",
        "                json.dump(self.loss_history, ofile, ensure_ascii=False, indent=2)\n",
        "            if metadata:\n",
        "                with open(os.path.join(checkpoint_dir, \"metadata.json\"), \"w+\", encoding='utf-8') as ofile:\n",
        "                    json.dump(metadata, ofile, ensure_ascii=False, indent=2)\n",
        "        else:\n",
        "            directory = '/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/BPE/'\n",
        "            torch.save(self.model, os.path.join(directory, \"model.pt\"))\n",
        "            with open(os.path.join(directory, \"loss.json\"), \"w+\", encoding='utf-8') as ofile:\n",
        "                json.dump(self.loss_history, ofile, ensure_ascii=False, indent=2)\n",
        "            if metadata:\n",
        "                with open(os.path.join(directory, \"metadata.json\"), \"w+\", encoding='utf-8') as ofile:\n",
        "                    json.dump(metadata, ofile, ensure_ascii=False, indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_paddings(sequence,pad_token):\n",
        "  while(sequence[-1] == pad_token):\n",
        "    sequence = sequence[:-1]\n",
        "\n",
        "  return sequence"
      ],
      "metadata": {
        "id": "cwsPhIlbfK7S"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rnn_greedy_generate(model, seq_x, max_length=5):\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    input_length = len(seq_x)\n",
        "\n",
        "    for i in range(5):\n",
        "      seq_x.append(0)\n",
        "    model.eval()\n",
        "    input_tokens = torch.tensor(seq_x).unsqueeze(0)\n",
        "    input_tokens = input_tokens.to(device)\n",
        "    output_probs,_ = model(input_tokens)\n",
        "    tgt_tokens = torch.argmax(output_probs, dim = 2).squeeze(0).tolist()\n",
        "    tgt_tokens = remove_paddings(tgt_tokens,0)\n",
        "    trans_seq = tgt_tokenizer_model.decode(tgt_tokens[:-1])\n",
        "\n",
        "    return trans_seq"
      ],
      "metadata": {
        "id": "Cuk-PTHBfMSD"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Evaluator:\n",
        "    \"\"\" Class to handle all the logic concerning the evaluation of trained models.  \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\" Initializes the evaluator.\n",
        "\n",
        "        Args:\n",
        "            src_tokenizer (Tokenizer): Tokenizer for input strings in the source language.\n",
        "            tgt_tokenizer (Tokenizer): Tokenizer for output strings in the target language.\n",
        "        \"\"\"\n",
        "\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.decoding_method = None\n",
        "\n",
        "    def set_decoding_method(self, decoding_method):\n",
        "        \"\"\" Sets the decoding method to use with models.\n",
        "                The evaluation function will use the set decoding method to generate outputs from the model.\n",
        "\n",
        "        Args:\n",
        "            decoding_method (function): Decoding method.\n",
        "                Must accept the model instance, the input string, and tokenizers as arguments.\n",
        "                Can accept additional arguments if required.\n",
        "        \"\"\"\n",
        "\n",
        "        self.decoding_method = decoding_method\n",
        "\n",
        "    @staticmethod\n",
        "    def decompose(string):\n",
        "        \"\"\" Decomposes a string into a set of tokens.\n",
        "\n",
        "        Args:\n",
        "            string (str): String to decompose.\n",
        "\n",
        "        Returns:\n",
        "            list[str]: List of characters from the string.\n",
        "        \"\"\"\n",
        "        return unicodedata.normalize('NFKD', string).encode('utf-8')\n",
        "\n",
        "    @staticmethod\n",
        "    def levenshtein_distance(string1, string2):\n",
        "        \"\"\" Computes the levensthein distance between two strings.\n",
        "\n",
        "        Args:\n",
        "            string1 (list[any]): Sequence A.\n",
        "            string2 (list[any]): Sequence B.\n",
        "\n",
        "        Returns:\n",
        "            tuple[int, int, int]: Number of insertions + deletions, substitutions and no-ops.\n",
        "        \"\"\"\n",
        "\n",
        "        costs = [\n",
        "            [ 0 for j in range(len(string2)+1) ]\n",
        "            for i in range(len(string1)+1)\n",
        "        ]\n",
        "\n",
        "        # Prepare matrix of costs.\n",
        "        for i in range(len(string1)+1): costs[i][0] = i\n",
        "        for j in range(len(string2)+1): costs[0][j] = j\n",
        "        for i in range(1, len(string1)+1):\n",
        "            for j in range(1, len(string2)+1):\n",
        "                costs[i][j] = min(\n",
        "                    costs[i][j-1] + 1,\n",
        "                    costs[i-1][j] + 1,\n",
        "                    costs[i-1][j-1] + (0 if string1[i-1] == string2[j-1] else 1)\n",
        "                )\n",
        "\n",
        "        # Decode matrix in backward manner for actual operation counts.\n",
        "        c_ins_del, c_sub, c_noop = 0, 0, 0\n",
        "\n",
        "        i, j = len(string1), len(string2)\n",
        "        while i > 0 or j > 0:\n",
        "            if i > 0 and costs[i][j] == costs[i-1][j] + 1:\n",
        "                c_ins_del += 1\n",
        "                i -= 1\n",
        "            elif j > 0 and costs[i][j] == costs[i][j-1] + 1:\n",
        "                c_ins_del += 1\n",
        "                j -= 1\n",
        "            elif i > 0 and j > 0:\n",
        "                if string1[i-1] == string2[j-1]:\n",
        "                    c_noop += 1\n",
        "                else:\n",
        "                    c_sub += 1\n",
        "                i, j = i-1, j-1\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        return c_ins_del, c_sub, c_noop\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy(y_true, y_pred):\n",
        "        \"\"\" Computes the accuracy of the predictions, against a reference set of predictions.\n",
        "\n",
        "        Args:\n",
        "            y_true (list[str]): Actual translations.\n",
        "            y_pred (list[str]): Generated translations.\n",
        "\n",
        "        Returns:\n",
        "            float: Accuracy score, between 0 and 1.\n",
        "        \"\"\"\n",
        "        return sum(yi_true == yi_pred for yi_true, yi_pred in zip(y_true, y_pred)) / len(y_pred)\n",
        "\n",
        "    @classmethod\n",
        "    def char_error_rate(cls, y_true, y_pred):\n",
        "        \"\"\" Computes the character level error rate (CER) of the set of\n",
        "            predictions against the reference translations.\n",
        "\n",
        "        Args:\n",
        "            y_true (list[str]): Actual translations.\n",
        "            y_pred (list[str]): Generated translations.\n",
        "\n",
        "        Returns:\n",
        "            float: CER score, between 0 and 1. Lower the better.\n",
        "        \"\"\"\n",
        "        cer_score = 0\n",
        "        for yi_true, yi_pred in zip(y_true, y_pred):\n",
        "            yi_true, yi_pred = cls.decompose(yi_true), cls.decompose(yi_pred)\n",
        "            c_ins_del, c_sub, c_noop = cls.levenshtein_distance(yi_true, yi_pred)\n",
        "            cer_score += (c_ins_del + c_sub) / (c_ins_del + c_sub + c_noop)\n",
        "\n",
        "        return cer_score / len(y_true)\n",
        "\n",
        "    def token_error_rate(self, y_true, y_pred):\n",
        "        \"\"\" Computes the token level error rate (TER) of the set of\n",
        "            predictions against the reference translations.\n",
        "\n",
        "        Args:\n",
        "            y_true (list[str]): Actual translations.\n",
        "            y_pred (list[str]): Generated translations.\n",
        "\n",
        "        Returns:\n",
        "            float: TER score, between 0 and 1. Lower the better.\n",
        "        \"\"\"\n",
        "\n",
        "        ter_score = 0\n",
        "\n",
        "        for yi_true, yi_pred in zip(y_true, y_pred):\n",
        "            yi_true = tgt_tokenizer_model.encode(yi_true)\n",
        "            yi_pred = tgt_tokenizer_model.encode(yi_pred)\n",
        "            t_ins_del, t_sub, t_noop = self.levenshtein_distance(yi_true, yi_pred)\n",
        "            ter_score += (t_ins_del + t_sub) / (t_ins_del + t_sub + t_noop)\n",
        "\n",
        "        return ter_score / len(y_true)\n",
        "\n",
        "    @classmethod\n",
        "    def bleu_score(cls, y_true, y_pred):\n",
        "        \"\"\" Computes the average BLEU score of the set of predictions against the reference translations.\n",
        "\n",
        "            Uses default parameters and equal weights for all n-grams, with max N = 4. (Thus computes BLEU-4).\n",
        "            Uses a smoothing method for the case of missing n-grams.\n",
        "\n",
        "        Args:\n",
        "            y_true (list[str]): Actual translations.\n",
        "            y_pred (list[str]): Generated translations.\n",
        "\n",
        "        Returns:\n",
        "            float: BLEU-4 score, the higher the better.\n",
        "        \"\"\"\n",
        "\n",
        "        y_true = [ [ cls.decompose(yi) ] for yi in y_true ]\n",
        "        y_pred = [ cls.decompose(yi) for yi in y_pred ]\n",
        "\n",
        "        smoothing = bleu_score.SmoothingFunction()\n",
        "\n",
        "        return bleu_score.corpus_bleu(\n",
        "            y_true, y_pred,\n",
        "            smoothing_function=smoothing.method1\n",
        "        )\n",
        "\n",
        "    def evaluate(self, model, data, reference_outputs):\n",
        "        \"\"\" Performs the evaluation of a specified model over given data.\n",
        "\n",
        "        Args:\n",
        "            model_path (str): Path to load the model from. Must have a model.pt file.\n",
        "            data (list[str]): List of input strings to translate.\n",
        "            reference_outputs (list[str]): List of output strings to use as reference.\n",
        "            decoding_kwargs (dict[str, any]): Additional arguments to forward to the decoding method.\n",
        "                This could be for instance, max_length for a greedy decoding method.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If the decoding method is not set apriori.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.decoding_method is None:\n",
        "            raise ValueError(f\"{self.evaluate.__name__}: no decoding method is set, assign before use.\")\n",
        "        model.to(self.device)\n",
        "        model.eval()\n",
        "\n",
        "        # Generate outputs.\n",
        "        generated_outputs = []\n",
        "        with torch.no_grad():\n",
        "            for seq_x in data:\n",
        "                generated_outputs.append(self.decoding_method(\n",
        "                    model, seq_x))\n",
        "        accuracy_score = self.accuracy(reference_outputs, generated_outputs)\n",
        "        blue_score     = self.bleu_score(reference_outputs, generated_outputs)\n",
        "\n",
        "        print(\"EVALUATION:\", \">\", \"accuracy:\", f\"{accuracy_score:.2%}\")\n",
        "        print(\"EVALUATION:\", \">\", \"BLEU    :\", f\"{blue_score:.4f}\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "A7mjzuHNfMU7"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample =df_test\n",
        "true_data = [tgt_tokenizer_model.decode(tokens) for tokens in df_sample['Hindi']]\n",
        "df_sample.shape"
      ],
      "metadata": {
        "id": "4YNhADnWfRiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c0d0cc-ad83-4fbb-cf0e-a05c8e06096b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6001, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "1hKS2woH3nmb"
      },
      "outputs": [],
      "source": [
        "rnn_enc_dec_attn_params = {\n",
        "    'src_vocab_size': 403,\n",
        "    'tgt_vocab_size': 403,\n",
        "    'embd_dims'     : 400,\n",
        "    'hidden_size'   : 800,\n",
        "    'dropout'       : 0.4,\n",
        "    'num_layers'    : 4,\n",
        "    'teacher_force_ratio' : 0.6\n",
        "}\n",
        "\n",
        "rnn_enc_dec_attn_training_params = dict(\n",
        "    num_epochs=15,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    save_steps=500,\n",
        "    eval_steps= 500\n",
        ")\n",
        "torch.manual_seed(42)\n",
        "model = RNNEncoderDecoderLMWithAttention(**rnn_enc_dec_attn_params)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)\n",
        "learning_rate = 0.001\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.NLLLoss()\n",
        "trainer = Trainer(\n",
        "    model, criterion, optimizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "BdiDgEnv3nsS"
      },
      "outputs": [],
      "source": [
        "train_dataset      = train_dataloader\n",
        "validation_dataset = valid_dataloader\n",
        "\n",
        "rnn_enc_dec_attn_train_data = dict(\n",
        "    train_dataset=train_dataset,\n",
        "    validation_dataset=validation_dataset,\n",
        ")\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "trainer.train(train_dataloader,valid_dataloader, **rnn_enc_dec_attn_training_params)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_enc_dec_attn_params = {\n",
        "    'src_vocab_size': 403,\n",
        "    'tgt_vocab_size': 403,\n",
        "    'embd_dims'     : 400,\n",
        "    'hidden_size'   : 800,\n",
        "    'dropout'       : 0.4,\n",
        "    'num_layers'    : 4,\n",
        "    'teacher_force_ratio' : 0.6\n",
        "}\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_path = '/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/BPE/model.pt'\n",
        "model_state_dict = torch.load(model_path,, map_location = device)\n",
        "model2 = RNNEncoderDecoderLMWithAttention(**rnn_enc_dec_attn_params)\n",
        "model2.load_state_dict(model_state_dict)\n",
        "model2 = model2.to(device)"
      ],
      "metadata": {
        "id": "XBl91yFNINlZ"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzNirWKDterR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26576606-bdee-4aa4-d8e8-08a15850c964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVALUATION: > accuracy: 5.00%\n",
            "EVALUATION: > BLEU    : 0.5962\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluator = Evaluator()\n",
        "evaluator.set_decoding_method(rnn_greedy_generate)\n",
        "evaluator.evaluate(\n",
        "    model2,\n",
        "    df_sample['English'], true_data\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
