{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmAyush/Video-Dubbing-with-Lip-Synchronization/blob/main/Text%20Translation/Word_tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ngCOhyRYlEbt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import pickle\n",
        "from io import open"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://drive.google.com/file/d/1ZjhBUE0w-SB6kO9_GFrrRIqCzKzGtQHC/view?usp=drive_link\"\n",
        "id = url.split('/')[-2]\n",
        "file_url = f'https://drive.google.com/uc?id={id}'\n",
        "destination_location = \"/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/\"\n",
        "gdown.download(file_url , destination_location, quiet=False )"
      ],
      "metadata": {
        "id": "e7Rtvfy6lRgp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "66b39ffb-0519-4599-8db9-d4f9cf449a46"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZjhBUE0w-SB6kO9_GFrrRIqCzKzGtQHC\n",
            "To: /content/Video-Dubbing-with-Lip-Synchronization/Text Translation/new_data.csv\n",
            "100%|██████████| 7.62M/7.62M [00:00<00:00, 97.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/new_data.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Video-Dubbing-with-Lip-Synchronization/Text Translation//new_data.csv')\n",
        "pairs = [[f\"{row['English']}\", f\"{row['Hindi']}\"] for index, row in df.iterrows()]"
      ],
      "metadata": {
        "id": "TuGL5-mnlRjh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_name = 'English'\n",
        "\n",
        "with open('/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/english.txt', 'w') as file:\n",
        "    for value in df[column_name]:\n",
        "        file.write(str(value) + '\\n')\n"
      ],
      "metadata": {
        "id": "d5Rh7zphlRmG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_name = 'Hindi'\n",
        "with open('/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/hindi.txt', 'w') as file:\n",
        "    for value in df[column_name]:\n",
        "        file.write(str(value) + '\\n')\n"
      ],
      "metadata": {
        "id": "yIB6k2SBlhJo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer_eng = Tokenizer(BPE())\n",
        "tokenizer_hin = Tokenizer(BPE())\n",
        "# Initialize a pre-tokenizer\n",
        "tokenizer_eng.pre_tokenizer = Whitespace()\n",
        "tokenizer_hin.pre_tokenizer = Whitespace()\n",
        "\n",
        "# Initialize a trainer\n",
        "trainer = BpeTrainer(special_tokens=[\n",
        "    \"<PAD>\",\n",
        "    \"<SOS>\",\n",
        "    \"<EOS>\",\n",
        "    \"<UNK>\",\n",
        "    \"<BOS>\",\n",
        "])\n",
        "\n",
        "# Training files\n",
        "eng_text = [\"/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/english.txt\"]\n",
        "hin_text = [\"/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/hindi.txt\"]\n",
        "# Train the tokenizer\n",
        "tokenizer_eng.train(eng_text, trainer)\n",
        "tokenizer_hin.train(hin_text, trainer)\n",
        "\n",
        "# Now you can encode text\n",
        "encoded1 = tokenizer_eng.encode(\"Hello, world!\")\n",
        "print(encoded1.ids)\n",
        "print(encoded1.tokens)\n",
        "\n",
        "encoded2 = tokenizer_hin.encode(\"राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है\")\n",
        "print(encoded2.ids)\n",
        "print(encoded2.tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL9cSIFBlhMz",
        "outputId": "08daa212-5157-4be7-9415-4642e32f9473"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[842, 16, 528, 5]\n",
            "['Hello', ',', 'world', '!']\n",
            "[5976, 780, 216, 172, 298, 305, 1033, 329, 362, 16, 214, 318, 179, 1403, 177, 160]\n",
            "['राजनीति', 'ज्ञ', 'ों', 'के', 'पास', 'जो', 'कार्य', 'करना', 'चाहिए', ',', 'वह', 'करने', 'कि', 'अनुमति', 'नहीं', 'है']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p 'src_word_tokenizer'\n",
        "with open('/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/english.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer_eng, f)\n",
        "\n",
        "# !mkdir -p 'tgt_word_tokenizer'\n",
        "with open('/content/Video-Dubbing-with-Lip-Synchronization/Text Translation/hindi.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer_hin, f)"
      ],
      "metadata": {
        "id": "jEr4pPCAlRo-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_vocab = tokenizer_eng.get_vocab()\n",
        "hin_vocab = tokenizer_hin.get_vocab()"
      ],
      "metadata": {
        "id": "tmDroZ-UoaNf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(eng_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF7BST37oaQS",
        "outputId": "03c747b2-7aaf-46e1-ca43-ce07c19325c9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29946"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}